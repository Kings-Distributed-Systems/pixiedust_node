{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Compute Protocol with Python and Node\n",
    "\n",
    "The idea behind this application is to demonstrate the unreasonable effectiveness of distributing tensorflow model inferencing and training jobs using a jupyter notebook with shared parameters with the python runtime. Allowing for data loading to be done in whatever language you're most familiar with and allowing you to parallelize whatever you may need to parallelize.\n",
    "\n",
    "![pixiedust_node](images/pixiedust_node_schematic.png)\n",
    "\n",
    "\n",
    "In the following cell, we initialize tensorflow, numpy and pixiedust_node. Pixiedust_node connects the ipython kernel to a node repl running in the background. \n",
    "\n",
    "We then initialize a few parameters for our identity keystore, our account keystore and the scheduler we'd like to target our jobs to go to. Addition, we clear the node instance `node.clear()`, we use `job-utility` to cancel all jobs running with our specific ID, Account and scheduler. `job-utility` must be installed globally using `npm install dcp-util -g`. Note that the exclamation marks are bash commands.\n",
    "\n",
    "Finally we install dcp-client in the specific npm location for the repl by using `npm.install`. \n",
    "\n",
    "\n",
    "\n",
    "### Note\n",
    "\n",
    "This is still an experimental tool and so sometimes pipes will die and consoles will go to the wrong place, please keep that in mind and just restart and clear all outputs if anything goes wrong.\n",
    "\n",
    "Pixiedust_node requires python 3.6 or below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.18</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixiedust_node 0.2.5 started. Cells starting '%%node' may contain Node.js code.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"margin:10px\"> \n",
       "            <a href=\"https://github.com/pixiedust/pixiedust_node\" target=\"_new\"> \n",
       "            <img src=\"https://github.com/pixiedust/pixiedust_node/raw/master/docs/_images/pdn_icon32.png\" style=\"float:left;margin-right:10px\"/> \n",
       "            </a> \n",
       "            <span>Pixiedust Node.js</span> \n",
       "            </div> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mgasmallah/.nvm/versions/node/v10.20.1/bin/npm install -s github:Kings-Distributed-Systems/npy-js\n",
      "+ npy-js@1.0.0\n",
      "updated 1 package and audited 1299 packages in 3.673s\n",
      "16 packages are looking for funding\n",
      "run `npm fund` for details\n",
      "found 24 vulnerabilities (8 low, 16 moderate)\n",
      "run `npm audit fix` to fix them, or `npm audit` for details\n",
      "Clearing context...\n",
      "Sending request cancelAllJobs...\n",
      "{\n",
      "  \"description\": \"Cancelled 0 jobs.\",\n",
      "  \"stats\": []\n",
      "}\n",
      "/home/mgasmallah/.nvm/versions/node/v10.20.1/bin/npm install -s dcp-client ntqdm lodash\n",
      "+ ntqdm@1.0.0\n",
      "+ lodash@4.17.20\n",
      "+ dcp-client@3.1.16-c\n",
      "updated 3 packages and audited 1299 packages in 4.713s\n",
      "15 packages are looking for funding\n",
      "run `npm fund` for details\n",
      "found 24 vulnerabilities (8 low, 16 moderate)\n",
      "run `npm audit fix` to fix them, or `npm audit` for details\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pixiedust_node\n",
    "\n",
    "ID_KEY_LOC  = '/home/mgasmallah/DCP/keys/id.keystore'\n",
    "ACC_KEY_LOC = '/home/mgasmallah/DCP/keys/AISTEST.keystore'\n",
    "SCHEDULER    = 'https://demo-scheduler.distributed.computer'\n",
    "\n",
    "node.clear();\n",
    "!job-utility cancelAllJobs -I $ID_KEY_LOC --default-bank-account-file $ACC_KEY_LOC --scheduler $SCHEDULER\n",
    "npm.install(['dcp-client', 'ntqdm', 'lodash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `%%node`\n",
    "\n",
    "Note that any cell with the magic `%%node` is now run on the node backend and any cell without this magic is in python and that any python variable of type `str`, `int`, `float`, `bool`, `dict`, or `list` will be moved to node when that cell is executed. Additionally, any variable declared with `var` in a `%%node` cell is automatically copied to the equivalent variable in python. The node and python variables are synced every second. \n",
    "\n",
    "Now that we have installed everything we need, we can initialize all the variables and values required for DCP to be used. In this case we add our ID key, account key and scheduler to the proccess argv in order to tell dcp where to find everything. Since there is no top level await, we simply use `initSync(process.argv)`. This allows us to now require `dcp/compute`, `dcp/wallet`, and `dcp/dcp-cli`. \n",
    "\n",
    "We also need an accountKeystore and an identityKeystore, however those are got asynchronously, so we'll initialize the variables here and fill them in later.\n",
    "\n",
    "This cell should only be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ... ... ...\n"
     ]
    }
   ],
   "source": [
    "%%node\n",
    "\n",
    "process.argv.push('-I', ID_KEY_LOC, '--default-bank-account-file',ACC_KEY_LOC, '--scheduler', SCHEDULER);\n",
    "require('dcp-client').initSync(process.argv)\n",
    "const tqdm = require('ntqdm');\n",
    "const _ = require('lodash');\n",
    "const compute = require('dcp/compute');\n",
    "const wallet = require('dcp/wallet');\n",
    "const dcpCli = require('dcp/dcp-cli');\n",
    "var identityKeystore;\n",
    "var accountKeystore;\n",
    "\n",
    "async function initKeystores(){\n",
    "    identityKeystore = await dcpCli.getIdentityKeystore();\n",
    "    accountKeystore  = await dcpCli.getAccountKeystore();\n",
    "    wallet.addId(identityKeystore);\n",
    "}\n",
    "\n",
    "await initKeystores();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ..... ..... ...\n",
      "|----------| 0/32 0% [elapsed: 00:00 left: 00:00, 0.00 iters/s]\n",
      "|----------| 1/32 3% [elapsed: 00:01 left: 00:31, 1.00 iters/s]\n",
      "|#---------| 2/32 6% [elapsed: 00:02 left: 00:30, 1.00 iters/s]\n",
      "|#---------| 3/32 9% [elapsed: 00:03 left: 00:29, 1.00 iters/s]\n",
      "|#---------| 4/32 12% [elapsed: 00:04 left: 00:28, 1.00 iters/s]\n",
      "|##--------| 5/32 15% [elapsed: 00:05 left: 00:27, 1.00 iters/s]\n",
      "|##--------| 6/32 18% [elapsed: 00:06 left: 00:26, 1.00 iters/s]\n",
      "|##--------| 7/32 21% [elapsed: 00:07 left: 00:25, 1.00 iters/s]\n",
      "|###-------| 8/32 25% [elapsed: 00:08 left: 00:24, 1.00 iters/s]\n",
      "|###-------| 9/32 28% [elapsed: 00:09 left: 00:23, 1.00 iters/s]\n",
      "|###-------| 10/32 31% [elapsed: 00:10 left: 00:22, 1.00 iters/s]\n",
      "|###-------| 11/32 34% [elapsed: 00:11 left: 00:21, 1.00 iters/s]\n",
      "|####------| 12/32 37% [elapsed: 00:12 left: 00:20, 1.00 iters/s]\n",
      "|####------| 13/32 40% [elapsed: 00:13 left: 00:19, 1.00 iters/s]\n",
      "|####------| 14/32 43% [elapsed: 00:14 left: 00:18, 1.00 iters/s]\n",
      "|#####-----| 15/32 46% [elapsed: 00:15 left: 00:17, 1.00 iters/s]\n",
      "|#####-----| 16/32 50% [elapsed: 00:16 left: 00:16, 1.00 iters/s]\n",
      "|#####-----| 17/32 53% [elapsed: 00:17 left: 00:15, 1.00 iters/s]\n"
     ]
    }
   ],
   "source": [
    "%%node\n",
    "async function m (){\n",
    "    for (let i of tqdm(_.range(0, 1000, 32))){\n",
    "        await new Promise((resolve,reject)=>{setTimeout(resolve,1000)});\n",
    "    }\n",
    "};\n",
    "await m();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "This is the first concrete simple example of distributing a job using DCP in a node cell. Since this process is asynchronous and doesn't quite sync up with ipython kernel, when this is run, you should wait until you have fully completed execution of the function. \n",
    "\n",
    "We begin by geting our identity keystore and our account keystore. Once these are loaded in we initialize our job using `compute.for`. `compute.for` takes an array of which each slice will be sent to a worker as an argument to the worker function. The worker function is the second argument and is what will be executed on each worker.\n",
    "\n",
    "We throw in some `job.on` overrides so we can log our progress through distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ..... ..... ..... ..... ..... ..... ..... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...\n",
      "Launching job\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 1, distributed: 1, computed: 0 }\n",
      "Job accepted...\n",
      "Got a status update:  { runStatus: 'WAITING', total: 1, distributed: 1, computed: 0 }\n",
      "Beginning require with index:  0\n",
      "{\"tfjs-core\":\"2.3.0\",\"tfjs-backend-cpu\":\"2.3.0\",\"tfjs-backend-webgl\":\"2.3.0\",\"tfjs-data\":\"2.3.0\",\"tfjs-layers\":\"2.3.0\",\"tfjs-converter\":\"2.3.0\",\"tfjs\":\"2.3.0\"}\n",
      "Got a status update:  { runStatus: 'WAITING', total: 1, distributed: 1, computed: 1 }\n",
      "Done executing job\n"
     ]
    }
   ],
   "source": [
    "%%node\n",
    "\n",
    "async function main(){\n",
    "    let job = compute.for([...Array(1).keys()], async function(sim_id){\n",
    "        progress(0.01);\n",
    "        console.log(\"Beginning require with index: \", sim_id);\n",
    "        const tf = require('aistensorflow/tfjs');\n",
    "        console.log(tf.version);\n",
    "        progress(1.0);\n",
    "        return \"done\";\n",
    "    });\n",
    "\n",
    "    job.on('accepted', ()=>{\n",
    "        console.log('Job accepted...');\n",
    "    });\n",
    "    job.on('status', (status)=>{\n",
    "        console.log('Got a status update: ', status);\n",
    "    });\n",
    "    job.on('console', (output)=>{\n",
    "        console.log(output.message);\n",
    "    });\n",
    "    job.on('error', (err)=>{\n",
    "        console.log(err);\n",
    "    });\n",
    "    job.requires('aistensorflow/tfjs');\n",
    "    job.public.name = 'dcp-testing';\n",
    "    console.log(\"Launching job\");\n",
    "    await job.exec(compute.marketValue, accountKeystore);\n",
    "    console.log(\"Done executing job\");\n",
    "};\n",
    "\n",
    "await main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python preprocessing\n",
    "\n",
    "Now let's demonstrate the neat things we can do with python-js bridging. Here we take advantage of the python tensorflow implementation which comes with mnist. We load this data in and do our data preprocessing in python.\n",
    "\n",
    "Once we have finished our data preprocessing, we convert the data to a list and initialize our results array in python as well. This allows us to sync to the js instance in the back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARpUlEQVR4nO3dfbBU9X3H8fenqJMRH5CaXglCCI7FqrXoIDoZUnUsPk0cRW0aZuyQ6kimIxMzk9A4tJ3oNBgnPjShcRLI+IAmRZKqFamJGDFia0q9IipijNZq5eYGtHjlIT4E+PaPPZgr7v72snv2wfv7vGbu3N39/s6eLwsfztk95+xPEYGZDX+/1+kGzKw9HHazTDjsZplw2M0y4bCbZcJhN8uEw24fIOkqSd8v6bluk/S14vanJD0/xOWGPNaGxmHvIpKmSXpM0puSNkv6D0kndrqvskTEoxExqZGxkl6W9Get627426fTDViFpIOA5cBfAz8E9gM+BbzTyb5s+PCWvXv8IUBELImInRHxVkSsiIinASQdIWmlpP+T9LqkH0gatXvhYss3V9LTkrZLullSj6QfS9oq6aeSDinGTpAUkmZL+pWkfklfrtWYpJOLPY4BSU9JOjUx9nhJa4p1LgU+Mqh2qqQNg+6fIOnJYuyPJC0dtMv/3lhJdwDjgfskbZP0N429xHlz2LvHL4GdkhZLOnt3MAcR8HXgY8AfAeOAq/YYcyEwncp/HOcCPwbmAR+l8nf9hT3GnwYcCZwBfKXabrKkscC/AV8DRgNfBu6S9NEqY/cD/hW4oxj7o6KnDyjG3gPcVoxdAsyoNjYi/hL4X+DciDggIr5RbZylOexdIiK2ANOAAL4HvCZpmaSeov5iRDwYEe9ExGvAjcApezzNP0XExojoAx4FVkfEkxHxNpVgHb/H+KsjYntEPAPcCsys0trFwP0RcX9E7IqIB4Fe4JwqY08G9gW+GRG/jYh/AR6v8Uc+mcrbyAXF2LuB/6r9ClmzHPYuEhHPRcTnIuJw4FgqW/FvAhS75HdK6pO0Bfg+cOgeT7Fx0O23qtw/YI/xrw66/Uqxvj19HPjzYhd+QNIAlf+UxlQZ+zGgL95/ddUr1f6sNca+WmOslcBh71IR8Qsqu7jHFg9dQ2Wr/8cRcRCVLa6aXM24QbfHA7+qMuZV4I6IGDXoZ2REXFtlbD8wVtLgvsbXWHe1seNqjIXKn92a4LB3CUlHSfqSpMOL++Oo7Fb/ZzHkQGAb8GbxPnpuCav9e0n7SzoG+CtgaZUx3wfOlXSmpBGSPlJ8eHZ4lbE/B3YAX5C0r6QLgKk11v1zYCcwR9I+ks5LjIXKXsrEof7B7IMc9u6xFTgJWC1pO5WQrwO+VNSvBk4A3qTygdndJazzEeBF4CHg+ohYseeAiHgVOI/KB32vUdnSz6XKv52IeBe4APgcsBn4i1p9Dhp7KTBAZU9lObUPNX4d+LvirUTNIwdWm/zlFfmRNAH4H2DfiNjR2W5+R9Jq4LsRcWunexmOvGW3jpF0iqTDit34WcBxwE863ddw5TPorJMmUTlbcCTwEnBRRPR3tqXhy7vxZpnwbrxZJtq6Gy/JuxFmLRYRVc+/aGrLLuksSc9LelHSlc08l5m1VsPv2SWNoHLxxnRgA5VzoGdGxPrEMt6ym7VYK7bsU4EXI+Kl4gSJO6mcfGFmXaiZsI/l/RcubCgee5/imuleSb1NrMvMmtTyD+giYhGwCLwbb9ZJzWzZ+3j/VUqHF4+ZWRdqJuyPA0dK+kTxrSOfBZaV05aZla3h3fiI2CFpDvAAMAK4JSKeLa0zMytVW0+X9Xt2s9ZryUk1Zvbh4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMNT9lsHw4jRoxI1g8++OCWrn/OnDk1a/vvv39y2UmTJiXrl19+ebJ+/fXX16zNnDkzuezbb7+drF977bXJ+tVXX52sd0JTYZf0MrAV2AnsiIgpZTRlZuUrY8t+WkS8XsLzmFkL+T27WSaaDXsAKyQ9IWl2tQGSZkvqldTb5LrMrAnN7sZPi4g+SX8APCjpFxGxavCAiFgELAKQFE2uz8wa1NSWPSL6it+bgHuAqWU0ZWblazjskkZKOnD3beAMYF1ZjZlZuZrZje8B7pG0+3n+OSJ+UkpXw8z48eOT9f322y9Z/+QnP5msT5s2rWZt1KhRyWUvvPDCZL2TNmzYkKwvWLAgWZ8xY0bN2tatW5PLPvXUU8n6I488kqx3o4bDHhEvAX9SYi9m1kI+9GaWCYfdLBMOu1kmHHazTDjsZplQRPtOahuuZ9BNnjw5WV+5cmWy3urLTLvVrl27kvVLLrkkWd+2bVvD6+7v70/W33jjjWT9+eefb3jdrRYRqva4t+xmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSZ8nL0Eo0ePTtZXr16drE+cOLHMdkpVr/eBgYFk/bTTTqtZe/fdd5PL5nr+QbN8nN0scw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4SnbC7B5s2bk/W5c+cm65/+9KeT9SeffDJZr/eVyilr165N1qdPn56sb9++PVk/5phjatauuOKK5LJWLm/ZzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNM+Hr2LnDQQQcl6/WmF164cGHN2qWXXppc9uKLL07WlyxZkqxb92n4enZJt0jaJGndoMdGS3pQ0gvF70PKbNbMyjeU3fjbgLP2eOxK4KGIOBJ4qLhvZl2sbtgjYhWw5/mg5wGLi9uLgfNL7svMStboufE9EbF7sqxfAz21BkqaDcxucD1mVpKmL4SJiEh98BYRi4BF4A/ozDqp0UNvGyWNASh+byqvJTNrhUbDvgyYVdyeBdxbTjtm1ip1d+MlLQFOBQ6VtAH4KnAt8ENJlwKvAJ9pZZPD3ZYtW5pa/s0332x42csuuyxZX7p0abJeb4516x51wx4RM2uUTi+5FzNrIZ8ua5YJh90sEw67WSYcdrNMOOxmmfAlrsPAyJEja9buu+++5LKnnHJKsn722Wcn6ytWrEjWrf08ZbNZ5hx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgkfZx/mjjjiiGR9zZo1yfrAwECy/vDDDyfrvb29NWs33XRTctl2/tscTnyc3SxzDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhI+zZ27GjBnJ+q233pqsH3jggQ2ve968ecn67bffnqz39/cn67nycXazzDnsZplw2M0y4bCbZcJhN8uEw26WCYfdLBM+zm5Jxx57bLJ+4403Juunn974ZL8LFy5M1ufPn5+s9/X1NbzuD7OGj7NLukXSJknrBj12laQ+SWuLn3PKbNbMyjeU3fjbgLOqPP6PETG5+Lm/3LbMrGx1wx4Rq4DNbejFzFqomQ/o5kh6utjNP6TWIEmzJfVKqv1lZGbWco2G/TvAEcBkoB+4odbAiFgUEVMiYkqD6zKzEjQU9ojYGBE7I2IX8D1garltmVnZGgq7pDGD7s4A1tUaa2bdoe5xdklLgFOBQ4GNwFeL+5OBAF4GPh8RdS8u9nH24WfUqFHJ+rnnnluzVu9aeanq4eL3rFy5MlmfPn16sj5c1TrOvs8QFpxZ5eGbm+7IzNrKp8uaZcJhN8uEw26WCYfdLBMOu1kmfImrdcw777yTrO+zT/pg0Y4dO5L1M888s2btZz/7WXLZDzN/lbRZ5hx2s0w47GaZcNjNMuGwm2XCYTfLhMNulom6V71Z3o477rhk/aKLLkrWTzzxxJq1esfR61m/fn2yvmrVqqaef7jxlt0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4SPsw9zkyZNStbnzJmTrF9wwQXJ+mGHHbbXPQ3Vzp07k/X+/vS3l+/atavMdj70vGU3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTJR9zi7pHHA7UAPlSmaF0XEtySNBpYCE6hM2/yZiHijda3mq96x7Jkzq020W1HvOPqECRMaaakUvb29yfr8+fOT9WXLlpXZzrA3lC37DuBLEXE0cDJwuaSjgSuBhyLiSOCh4r6Zdam6YY+I/ohYU9zeCjwHjAXOAxYXwxYD57eqSTNr3l69Z5c0ATgeWA30RMTu8xV/TWU338y61JDPjZd0AHAX8MWI2CL9bjqpiIha87hJmg3MbrZRM2vOkLbskvalEvQfRMTdxcMbJY0p6mOATdWWjYhFETElIqaU0bCZNaZu2FXZhN8MPBcRNw4qLQNmFbdnAfeW356ZlaXulM2SpgGPAs8Au68ZnEflffsPgfHAK1QOvW2u81xZTtnc05P+OOPoo49O1r/97W8n60cdddRe91SW1atXJ+vXXXddzdq996a3D75EtTG1pmyu+549Iv4dqLowcHozTZlZ+/gMOrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJf5X0EI0ePbpmbeHChcllJ0+enKxPnDixoZ7K8NhjjyXrN9xwQ7L+wAMPJOtvvfXWXvdkreEtu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WiWyOs5900knJ+ty5c5P1qVOn1qyNHTu2oZ7K8pvf/KZmbcGCBcllr7nmmmR9+/btDfVk3cdbdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sE9kcZ58xY0ZT9WasX78+WV++fHmyvmPHjmQ9dc35wMBAclnLh7fsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmhjI/+zjgdqAHCGBRRHxL0lXAZcBrxdB5EXF/nefKcn52s3aqNT/7UMI+BhgTEWskHQg8AZwPfAbYFhHXD7UJh92s9WqFve4ZdBHRD/QXt7dKeg7o7FezmNle26v37JImAMcDq4uH5kh6WtItkg6pscxsSb2Sepvq1MyaUnc3/r2B0gHAI8D8iLhbUg/wOpX38f9AZVf/kjrP4d14sxZr+D07gKR9geXAAxFxY5X6BGB5RBxb53kcdrMWqxX2urvxkgTcDDw3OOjFB3e7zQDWNdukmbXOUD6NnwY8CjwD7CoengfMBCZT2Y1/Gfh88WFe6rm8ZTdrsaZ248visJu1XsO78WY2PDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WiXZP2fw68Mqg+4cWj3Wjbu2tW/sC99aoMnv7eK1CW69n/8DKpd6ImNKxBhK6tbdu7QvcW6Pa1Zt3480y4bCbZaLTYV/U4fWndGtv3doXuLdGtaW3jr5nN7P26fSW3czaxGE3y0RHwi7pLEnPS3pR0pWd6KEWSS9LekbS2k7PT1fMobdJ0rpBj42W9KCkF4rfVefY61BvV0nqK167tZLO6VBv4yQ9LGm9pGclXVE83tHXLtFXW163tr9nlzQC+CUwHdgAPA7MjIj1bW2kBkkvA1MiouMnYEj6U2AbcPvuqbUkfQPYHBHXFv9RHhIRX+mS3q5iL6fxblFvtaYZ/xwdfO3KnP68EZ3Ysk8FXoyIlyLiXeBO4LwO9NH1ImIVsHmPh88DFhe3F1P5x9J2NXrrChHRHxFrittbgd3TjHf0tUv01RadCPtY4NVB9zfQXfO9B7BC0hOSZne6mSp6Bk2z9Wugp5PNVFF3Gu922mOa8a557RqZ/rxZ/oDug6ZFxAnA2cDlxe5qV4rKe7BuOnb6HeAIKnMA9gM3dLKZYprxu4AvRsSWwbVOvnZV+mrL69aJsPcB4wbdP7x4rCtERF/xexNwD5W3Hd1k4+4ZdIvfmzrcz3siYmNE7IyIXcD36OBrV0wzfhfwg4i4u3i4469dtb7a9bp1IuyPA0dK+oSk/YDPAss60McHSBpZfHCCpJHAGXTfVNTLgFnF7VnAvR3s5X26ZRrvWtOM0+HXruPTn0dE23+Ac6h8Iv/fwN92oocafU0Enip+nu10b8ASKrt1v6Xy2calwO8DDwEvAD8FRndRb3dQmdr7aSrBGtOh3qZR2UV/Glhb/JzT6dcu0VdbXjefLmuWCX9AZ5YJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtl4v8BEQvLOPY5q1AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#Change datatype\n",
    "x_train = x_train.astype(np.uint8)\n",
    "x_test  = x_test.astype(np.uint8)\n",
    "\n",
    "plt.imshow(x_train[0,...], cmap='gray')\n",
    "plt.title(\"Sample digit\")\n",
    "plt.show()\n",
    "\n",
    "#change [60000] to [60000,10] (one_hot)\n",
    "y_train = tf.one_hot(y_train, 10).numpy()\n",
    "y_test  = tf.one_hot(y_test, 10).numpy()\n",
    "\n",
    "#reshape from a [-1,28,28] to a [-1,783] \n",
    "x_train = x_train.reshape(-1,784)\n",
    "x_test  = x_test.reshape(-1, 784)\n",
    "\n",
    "#We choose the first 1000 samples for training and reshape to [-1] and convert to a list\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "#initialize a list to use in js and python\n",
    "mnistResults = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we confirm that the arrays have been send to the js instance by logging their type and their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 60000, 784 ] 'uint8' [ 60000, 10 ] 'float32'\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%node\n",
    "console.log(x_train.shape, x_train.dtype, y_train.shape, y_train.dtype);\n",
    "console.log(mnistResults);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split up our data into batches to send off to the protocol for training. This is (for the majority) the same as previous main function, but does a few things more in splitting up the data and in adding to the work function. In this example we use the `job.requires` syntax to require tensorflowjs in each of our workers. Although you could `npm.install( '@tensorflow/tfjs')` and `job.requires('@tensorflow/tfjs')`, we provide a module on DCP called `aistensorflow/tfjs` which has all of tfjs and is confirmed working for DCP.\n",
    "\n",
    "Finally, note that we have added on the `job.on(results,()....` a push to the `mnistResults` variable declared in python above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ... ... ... ... ... ... ... ..... ..... ..... ..... ... ... ..... ..... ..... ..... ..... ..... ....... ....... ....... ....... ....... ....... ....... ..... ..... ....... ....... ....... ....... ..... ..... ..... ..... ..... ....... ....... ......... ........... ........... ......... ....... ..... ..... ..... ..... ..... ..... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...\n",
      "Launching job\n",
      "Job accepted...\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 5, distributed: 0, computed: 0 }\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 5, distributed: 1, computed: 0 }\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 5, distributed: 2, computed: 0 }\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 5, distributed: 3, computed: 0 }\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 5, distributed: 4, computed: 0 }\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 5, distributed: 5, computed: 0 }\n",
      "Got a status update:  { runStatus: 'WAITING', total: 5, distributed: 5, computed: 1 }\n",
      "Got a status update:  { runStatus: 'WAITING', total: 5, distributed: 5, computed: 2 }\n",
      "Got a status update:  { runStatus: 'WAITING', total: 5, distributed: 5, computed: 3 }\n",
      "Got a status update:  { runStatus: 'WAITING', total: 5, distributed: 5, computed: 4 }\n",
      "Got a status update:  { runStatus: 'WAITING', total: 5, distributed: 5, computed: 5 }\n",
      "Done executing job\n",
      "Number of results:  5\n"
     ]
    }
   ],
   "source": [
    "%%node\n",
    "\n",
    "async function main(){\n",
    "    let xtrain = x_train.typedArray;\n",
    "    let ytrain = y_train.typedArray;\n",
    "    let batch = 32;\n",
    "    \n",
    "    \n",
    "    let trainingArray = [];\n",
    "    \n",
    "    for (let i=0;i< batch*5;i+=batch){\n",
    "        let xs = Array.from(xtrain.slice(i*784, Math.min(xtrain.length, (i+batch)*784)));\n",
    "        let ys = Array.from(ytrain.slice(i*10, Math.min(ytrain.length, (i+batch)*10)));\n",
    "        trainingArray.push({xs, ys, batch});\n",
    "    }\n",
    "    \n",
    "    let job = compute.for(trainingArray, async function(data){\n",
    "        progress();\n",
    "        const tf = require('aistensorflow/tfjs');\n",
    "        tf.setBackend('cpu');\n",
    "        await tf.ready();\n",
    "        \n",
    "        const model = tf.sequential({\n",
    "            layers: [\n",
    "                tf.layers.dense({inputShape: [784], units:32, activation: 'relu'}),\n",
    "                tf.layers.dense({units: 64, activation: 'relu'}),\n",
    "                tf.layers.dense({units: 128, activation: 'relu'}),\n",
    "                tf.layers.dense({units: 10, activation: 'softmax'})\n",
    "            ]\n",
    "        });\n",
    "        progress();\n",
    "        model.compile({\n",
    "            optimizer: 'sgd',\n",
    "            loss: 'categoricalCrossentropy',\n",
    "            metrics: ['accuracy']\n",
    "        })\n",
    "    \n",
    "        let xTrain = tf.tensor(data.xs, [data.xs.length/784, 784], dtype='float32');\n",
    "        let yTrain = tf.tensor(data.ys, [data.ys.length/10, 10], dtype='int32');\n",
    "        \n",
    "        const history = await model.fit(xTrain, yTrain, {\n",
    "            epochs: 5,\n",
    "            callbacks: {\n",
    "                onEpochEnd: async (epochs, logs)=>{\n",
    "                    progress();\n",
    "                }\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        xTrain.dispose();\n",
    "        yTrain.dispose();\n",
    "        progress(1.0);\n",
    "        return history.history.acc;\n",
    "    });\n",
    "\n",
    "    job.on('accepted', ()=>{\n",
    "        console.log('Job accepted...');\n",
    "    });\n",
    "    job.on('status', (status)=>{\n",
    "        console.log('Got a status update: ', status);\n",
    "    });\n",
    "    job.on('result', (value)=>{\n",
    "        let result = value.result;\n",
    "        mnistResults.push(result[result.length-1]);   \n",
    "    });\n",
    "    job.on('console', (output)=>{\n",
    "        console.log(output.message);\n",
    "    });\n",
    "    job.on('error', (err)=>{\n",
    "        console.log(err);\n",
    "    });\n",
    "    job.requires('aistensorflow/tfjs');\n",
    "    job.public.name = 'dcp-vae-testing';\n",
    "    console.log(\"Launching job\");\n",
    "    await job.exec(compute.marketValue, accountKeystore);\n",
    "    console.log(\"Done executing job\");\n",
    "    console.log(\"Number of results: \", mnistResults.length);\n",
    "};\n",
    "\n",
    "await main();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Visualization \n",
    "Now that we have all these results and they are available in python, we can do some very quick data visualization in python! Here we use matplotlibs pyplot to plot the accuracies of each worker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mnistResults)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow to DCP\n",
    "\n",
    "In this section we will train a model in python, convert it to js and ship it off to DCP as a module that we can require. First we begin by requiring the python tensorflowjs package which allows for python to js conversion of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflowjs as tfjs\n",
    "except:\n",
    "    !pip install tensorflowjs tf-estimator-nightly\n",
    "    import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply use the mnist dataset to train a simple network on mnist in python and evaluate it's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 564us/step - loss: 0.2975 - accuracy: 0.9128\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 593us/step - loss: 0.1481 - accuracy: 0.9554\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 558us/step - loss: 0.1116 - accuracy: 0.9656\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 565us/step - loss: 0.0895 - accuracy: 0.9721\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 550us/step - loss: 0.0762 - accuracy: 0.9753\n",
      "313/313 [==============================] - 0s 444us/step - loss: 0.0741 - accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)\n",
    "del x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using tensorflowjs in python and a tensorflowjs utility we have built, we can save the model to a directory and publish this model to DCP. Note that the `-p` package version number must be incremented everytime if the package name `dcp_mnist_ex/mnist.js` is not changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./tfjs_model’: File exists\n",
      "group1-shard1of1.bin  model.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgasmallah/anaconda3/envs/test/lib/python3.6/site-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  return h5py.File(h5file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10 11:14:10.645976: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-09-10 11:14:10.693173: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599990000 Hz\n",
      "2020-09-10 11:14:10.693624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ef2c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-10 11:14:10.693639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Module published at :  dcp_mnist_ex/mnist.js\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "!mkdir './tfjs_model'\n",
    "tfjs.converters.save_keras_model(model, './tfjs_model')\n",
    "!ls './tfjs_model'\n",
    "!node ~/DCP/dcp-utils/tfjs_utils/bin/serializeModel.js -m ./tfjs_model/model.json -o dcp_mnist_ex/mnist.js -p 1.0.11 -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to use this model is pretty trivial. We use the same `x_train`and `y_train` variables in node that we had from before and batch them for inference using our model. We require `aistensorflow/tfjs` and `dcp_mnist_ex/mnist.js` as well as `dcp-polyfills/polyfills.js`. This allows us to `await require('mnist').getModel()` to get the mnist model we built. In order to evaluate we have to compile the model with a loss and an accuracy. Finally we evaluate the model and return our accuracy. We have reset mnistResults and so we can use it to fill it in with our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ... ... ... ... ... ... ... ..... ..... ..... ..... ... ... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ....... ....... ....... ....... ..... ..... ....... ....... ..... ..... ..... ..... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...\n",
      "Launching job\n",
      "Job accepted...\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 1, distributed: 0, computed: 0 }\n",
      "Got a status update:  { runStatus: 'SLOWWORK', total: 1, distributed: 1, computed: 0 }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "stack:\n",
      "'TypeError: result.dataSync is not a function\\n    at eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:35:23)\\n    at async eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:11:32)',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null,\n",
      "lineNumber: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "lineNumber: 35,\n",
      "columnNumber: 23,\n",
      "stack:\n",
      "'result<@blob:https://dcp.work/3ed75691-3d65-49d4-bb55-d954cb219984 line 645 > eval:35:23\\n',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "lineNumber: 35,\n",
      "columnNumber: 23,\n",
      "stack:\n",
      "'result<@blob:https://dcp.work/ee9c047a-7d7b-4c93-8caf-5855e5992b86 line 645 > eval:35:23\\n',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "stack:\n",
      "'TypeError: result.dataSync is not a function\\n    at eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:35:23)\\n    at async eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:11:32)',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null,\n",
      "lineNumber: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "lineNumber: 35,\n",
      "columnNumber: 23,\n",
      "stack:\n",
      "'result<@blob:https://dcp.work/0fec2fa0-b8ef-4e05-804b-ebc3a81cdc1d line 645 > eval:35:23\\n',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "lineNumber: 35,\n",
      "columnNumber: 23,\n",
      "stack:\n",
      "'result<@blob:https://dcp.work/039734ca-f391-43bd-a816-bd9866b3c705 line 645 > eval:35:23\\n',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "stack:\n",
      "'TypeError: result.dataSync is not a function\\n    at eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:35:23)\\n    at async eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:11:32)',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null,\n",
      "lineNumber: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "lineNumber: 35,\n",
      "columnNumber: 23,\n",
      "stack:\n",
      "'result<@blob:https://dcp.work/56274ce5-37c5-42ae-b0ec-9f83c4e20f06 line 645 > eval:35:23\\n',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "stack:\n",
      "'TypeError: result.dataSync is not a function\\n    at eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:35:23)\\n    at async eval (eval at workerBootstrap$messageHandler (eval at receiveLine (unknown source)), <anonymous>:11:32)',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null,\n",
      "lineNumber: null }\n",
      "[32,28,28]\n",
      "\n",
      "{ message: 'result.dataSync is not a function',\n",
      "name: 'TypeError',\n",
      "lineNumber: 35,\n",
      "columnNumber: 23,\n",
      "stack:\n",
      "'result<@blob:https://dcp.work/22477b7a-b705-49f8-94d6-c42268562987 line 645 > eval:35:23\\n',\n",
      "address: 'qdAGAguC4LUOImpTyXOVFV',\n",
      "sliceIndex: 0,\n",
      "fileName: null }\n",
      "Thrown:\n",
      "Error: Cancel - triggered by ETOOMANYERRORS.\n",
      "at onCancel (/home/mgasmallah/node/node_modules/dcp-client/dist/dcp-client-bundle.js:16:121655)\n",
      "at Function.(anonymous function).events.once (/home/mgasmallah/node/node_modules/dcp-client/dist/dcp-client-bundle.js:16:121773)\n",
      "at e.EventEmitter.once_wrapper (/home/mgasmallah/node/node_modules/dcp-client/dist/dcp-client-bundle.js:16:63244)\n",
      "at i (/home/mgasmallah/node/node_modules/dcp-client/dist/dcp-client-bundle.js:16:65336)\n"
     ]
    }
   ],
   "source": [
    "%%node\n",
    "mnistResults = [];\n",
    "async function main(){\n",
    "    let xtrain = x_train.typedArray;\n",
    "    let ytrain = y_train.typedArray;\n",
    "    let batch = 32;\n",
    "    \n",
    "    \n",
    "    let trainingArray = [];\n",
    "    \n",
    "    for (let i=0;i< 10;i+=batch){\n",
    "        let xs = Array.from(xtrain.slice(i*784, Math.min(xtrain.length, (i+batch)*784)));\n",
    "        let ys = Array.from(ytrain.slice(i*10, Math.min(ytrain.length, (i+batch)*10)));\n",
    "        trainingArray.push({xs, ys, batch});\n",
    "    }\n",
    "    \n",
    "    let job = compute.for(trainingArray, async function(data){\n",
    "        progress();\n",
    "        require('polyfills');\n",
    "        const tf = require('aistensorflow/tfjs');\n",
    "        tf.setBackend('cpu');\n",
    "        await tf.ready();\n",
    "        \n",
    "        const model = await require('mnist').getModel();\n",
    "        \n",
    "        let xTrain = tf.tensor(data.xs, [data.xs.length/784, 28, 28], dtype='float32');\n",
    "        let yTrain = tf.tensor(data.ys, [data.ys.length/10, 10], dtype='int32');\n",
    "        \n",
    "        \n",
    "        model.compile({\n",
    "            optimizer: 'sgd',\n",
    "            loss: 'categoricalCrossentropy',\n",
    "            metrics: ['accuracy']\n",
    "        })\n",
    "        \n",
    "        const result = model.evaluate(xTrain, yTrain, {\n",
    "            batchSize: 32,\n",
    "        });\n",
    "        console.log(xTrain.shape);\n",
    "        progress(1.0);\n",
    "        return result.dataSync()[0];\n",
    "    });\n",
    "\n",
    "    job.on('accepted', ()=>{\n",
    "        console.log('Job accepted...');\n",
    "    });\n",
    "    job.on('status', (status)=>{\n",
    "        console.log('Got a status update: ', status);\n",
    "    });\n",
    "    job.on('result', (value)=>{\n",
    "        mnistResults.push(value.result);\n",
    "        \n",
    "    });\n",
    "    job.on('console', (output)=>{\n",
    "        console.log(output.message);\n",
    "    });\n",
    "    job.on('error', (err)=>{\n",
    "        console.log(err);\n",
    "    });\n",
    "    \n",
    "    job.requires('dcp-polyfills/polyfills');\n",
    "    job.requires('aistensorflow/tfjs');\n",
    "    job.requires('dcp_mnist_ex/mnist');\n",
    "    \n",
    "    \n",
    "    job.public.name = 'dcp-vae-testing';\n",
    "    console.log(\"Launching job\");\n",
    "    await job.exec(compute.marketValue, accountKeystore);\n",
    "    console.log(\"Done executing job\");\n",
    "};\n",
    "\n",
    "await main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for entire set: \", sum(mnistResults)/len(mnistResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import pixiedust_node\n",
    "except:\n",
    "    !pip install pixiedust pixiedust_node\n",
    "    import pixiedust_node\n",
    "\n",
    "ID_KEY_LOC  = '/home/mgasmallah/DCP/keys/office/id.keystore'#'/home/mgasmallah/DCP/keys/id.keystore'\n",
    "ACC_KEY_LOC = '/home/mgasmallah/DCP/keys/office/default.keystore'#'/home/mgasmallah/DCP/keys/AISTEST.keystore'\n",
    "SCHEDULER    = 'http://scheduler.hamada.office.kingsds.network/'#'https://demo-scheduler.distributed.computer'\n",
    "\n",
    "node.clear();\n",
    "!job-utility cancelAllJobs -I $ID_KEY_LOC --default-bank-account-file $ACC_KEY_LOC --scheduler $SCHEDULER\n",
    "npm.install( 'dcp-client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "\n",
    "process.argv.push('-I', ID_KEY_LOC, '--default-bank-account-file',ACC_KEY_LOC, '--scheduler', SCHEDULER);\n",
    "require('dcp-client').initSync(process.argv)\n",
    "const tf = require('@tensorflow/tfjs');\n",
    "const compute = require('dcp/compute');\n",
    "const wallet = require('dcp/wallet');\n",
    "const dcpCli = require('dcp/dcp-cli');\n",
    "var accountKeystore;\n",
    "var identityKeystore;\n",
    "\n",
    "(async function main(){\n",
    "    identityKeystore = await dcpCli.getIdentityKeystore();\n",
    "    wallet.addId(identityKeystore);\n",
    "    accountKeystore = await dcpCli.getAccountKeystore();\n",
    "})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = np.expand_dims(train_images,axis=-1) / 255.\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1).tolist()\n",
    "latentDims = 10\n",
    "numIterations = 2\n",
    "numEpochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "\n",
    "mnistResults = [];\n",
    "\n",
    "function getWeights(model){\n",
    "    return tf.tidy(()=>{\n",
    "        let w = model.getWeights();\n",
    "        let retWeights = [];\n",
    "        for (let i = 0; i < w.length; i++){\n",
    "            retWeights.push({data: w[i].arraySync(), shape: w[i].shape });\n",
    "        }\n",
    "        return retWeights;\n",
    "    });\n",
    "}\n",
    "\n",
    "function setWeights(model, weightsObj){\n",
    "    return tf.tidy(()=>{\n",
    "        let w = [];\n",
    "        for (let i = 0; i < weightsObj.length; i++){\n",
    "            w.push(tf.tensor(weightsObj[i].data, weightsObj[i].shape));\n",
    "        }\n",
    "        model.setWeights(w);\n",
    "        return model;\n",
    "    });\n",
    "}\n",
    "\n",
    "function averageWeights(ws){\n",
    "    return tf.tidy(()=>{\n",
    "        let outWeights = [];\n",
    "        for (let i = 0; i < ws[0].length; i++){\n",
    "            let w = [];\n",
    "            for (let j = 0; j < ws.length; j++){\n",
    "                w.push(ws[j][i].data);\n",
    "            }\n",
    "            let shape = ws[0][i].shape;\n",
    "            shape = [w.length, ...shape];\n",
    "            w = tf.tensor(w, shape).mean(axis=0);\n",
    "            outWeights.push({data: w.arraySync(), shape: w.shape });\n",
    "        }\n",
    "        return outWeights;\n",
    "    });\n",
    "}\n",
    "\n",
    "\n",
    "async function main(){\n",
    "    \n",
    "    let xtrain = Float32Array.from(train_images);\n",
    "    let batch = 32;\n",
    "\n",
    "    let trainingArray = [];\n",
    "    let allEncoderWeights = [];\n",
    "    let allDecoderWeights = [];\n",
    "    \n",
    "    for (let i=0;i< Math.floor(xtrain.length/784);i+=batch){\n",
    "        let xs = Array.from(xtrain.slice(i*784, Math.min(xtrain.length, (i+batch)*784)));\n",
    "        trainingArray.push({xs, latentDims, numIterations, batch});\n",
    "    }\n",
    "    \n",
    "    \n",
    "    let encoder = tf.sequential({\n",
    "        layers: [\n",
    "            tf.layers.conv2d({filters: 32, kernelSize: 3, strides: 2, activation: 'relu', inputShape: [28, 28, 1]}),\n",
    "            tf.layers.conv2d({filters: 64, kernelSize: 3, strides: 2, activation: 'relu'}),\n",
    "            tf.layers.flatten(),\n",
    "            tf.layers.dense({units: latentDims + latentDims })\n",
    "        ]\n",
    "    });\n",
    "    \n",
    "    let decoder = tf.sequential({\n",
    "        layers: [\n",
    "            tf.layers.dense({ units: 7*7*32, activation: 'relu', inputShape: [latentDims]}),\n",
    "            tf.layers.reshape({ targetShape: [7,7,32]}),\n",
    "            tf.layers.conv2dTranspose({filters: 64, kernelSize: 3, strides: 2, padding: 'same',\n",
    "                                      activation: 'relu'}),\n",
    "            tf.layers.conv2dTranspose({filters: 32, kernelSize: 3, strides: 2, padding: 'same',\n",
    "                                      activation: 'relu'}),\n",
    "            tf.layers.conv2dTranspose({filters: 1, kernelSize: 3, strides: 1, padding: 'same'}),\n",
    "        ]\n",
    "    });\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for (let e = 0; e < numEpochs; e++){\n",
    "    \n",
    "        let encoderWeights = getWeights(encoder);\n",
    "        let decoderWeights = getWeights(decoder);\n",
    "        \n",
    "        let job = compute.for(trainingArray, async function(data, eWeights, dWeights){\n",
    "            progress();\n",
    "            require('polyfills');\n",
    "            const tf = require('aistensorflow/tfjs');\n",
    "            tf.setBackend('cpu');\n",
    "            await tf.ready();\n",
    "            \n",
    "            function getWeights(model){\n",
    "                return tf.tidy(()=>{\n",
    "                    let w = model.getWeights();\n",
    "                    let retWeights = [];\n",
    "                    for (let i = 0; i < w.length; i++){\n",
    "                        retWeights.push({data: w[i].arraySync(), shape: w[i].shape });\n",
    "                    }\n",
    "                    return retWeights;\n",
    "                });\n",
    "            };\n",
    "            \n",
    "            function setWeights(model, weightsObj){\n",
    "                return tf.tidy(()=>{\n",
    "                    let w = [];\n",
    "                    for (let i = 0; i < weightsObj.length; i++){\n",
    "                        w.push(tf.tensor(weightsObj[i].data, weightsObj[i].shape));\n",
    "                    }\n",
    "                    model.setWeights(w);\n",
    "                    return model;\n",
    "                });\n",
    "            }\n",
    "            \n",
    "            progress();\n",
    "            \n",
    "            let encoder = tf.sequential({\n",
    "                layers: [\n",
    "                    tf.layers.conv2d({filters: 32, kernelSize: 3, strides: 2, activation: 'relu', inputShape: [28, 28, 1]}),\n",
    "                    tf.layers.conv2d({filters: 64, kernelSize: 3, strides: 2, activation: 'relu'}),\n",
    "                    tf.layers.flatten(),\n",
    "                    tf.layers.dense({units: data.latentDims + data.latentDims })\n",
    "                ]\n",
    "            });\n",
    "            progress();\n",
    "            let decoder = tf.sequential({\n",
    "                layers: [\n",
    "                    tf.layers.dense({ units: 7*7*32, activation: 'relu', inputShape: [data.latentDims]}),\n",
    "                    tf.layers.reshape({ targetShape: [7,7,32]}),\n",
    "                    tf.layers.conv2dTranspose({filters: 64, kernelSize: 3, strides: 2, padding: 'same',\n",
    "                                              activation: 'relu'}),\n",
    "                    tf.layers.conv2dTranspose({filters: 32, kernelSize: 3, strides: 2, padding: 'same',\n",
    "                                              activation: 'relu'}),\n",
    "                    tf.layers.conv2dTranspose({filters: 1, kernelSize: 3, strides: 1, padding: 'same'}),\n",
    "                ]\n",
    "            });\n",
    "            progress();\n",
    "            \n",
    "            \n",
    "            encoder = setWeights(encoder, eWeights);\n",
    "            decoder = setWeights(decoder, dWeights);\n",
    "            \n",
    "            \n",
    "            const encode = (x)=>{\n",
    "                progress();\n",
    "                const [ mean, logvar ] = tf.split(encoder.predict(x), 2, 1);\n",
    "                progress();\n",
    "                return  [ mean, logvar ];            \n",
    "            };\n",
    "            const decode = (z, applySigmoid)=>{\n",
    "                progress();\n",
    "                let logits = decoder.predict(z);\n",
    "                progress();\n",
    "                if (applySigmoid){\n",
    "                    progress();\n",
    "                    let probs = tf.sigmoid(logits);\n",
    "                    return probs;\n",
    "                }\n",
    "                return logits;\n",
    "            }\n",
    "\n",
    "\n",
    "            progress();\n",
    "            const sample = (eps)=>{\n",
    "                progress();\n",
    "                if (typeof eps === 'undefined'){\n",
    "                    eps = tf.randomNormal([32, data.latentDims]);\n",
    "                }\n",
    "                return decode(eps, applySigmoid=true);\n",
    "            };\n",
    "\n",
    "            const reparameterize = (mean, logvar)=>{\n",
    "                progress();\n",
    "                let eps = tf.randomNormal([mean.shape[0], data.latentDims]);\n",
    "                progress();\n",
    "                return eps.mul(tf.exp(logvar.mul(.5))).add(mean);\n",
    "            };\n",
    "\n",
    "            const logNormalPdf = (sample, mean, logvar, raxis=1)=>{\n",
    "                progress();\n",
    "                let log2pi = tf.log(Math.PI * 2.)\n",
    "                let diff = (sample.sub(mean)).pow(2);\n",
    "                progress();\n",
    "                diff = diff.mul(-.5);\n",
    "                diff = diff.mul(tf.exp(logvar.mul(-1)));\n",
    "                progress();\n",
    "                diff = diff.add(logvar);\n",
    "                diff = diff.add(log2pi);\n",
    "                progress();\n",
    "                return tf.sum(diff, raxis);\n",
    "            }; \n",
    "\n",
    "            const computeLoss = (x)=>{\n",
    "                return tf.tidy(()=>{\n",
    "                    progress();\n",
    "                    const [mean, logvar] = encode(x);\n",
    "                    progress();\n",
    "                    const z = reparameterize( mean, logvar);\n",
    "                    progress();\n",
    "                    const xLogit = decode(z);\n",
    "                    progress();\n",
    "                    const crossEntropy = tf.losses.sigmoidCrossEntropy(x, xLogit, undefined, undefined, tf.Reduction.NONE);\n",
    "                    progress();\n",
    "                    const logpxZ = tf.sum(crossEntropy, axis=[1,2,3]).mul(-1);\n",
    "                    progress();\n",
    "                    const logpz = logNormalPdf(z, tf.tensor(0.),tf.tensor(0.));\n",
    "                    progress();\n",
    "                    const logqzX = logNormalPdf(z, mean, logvar);\n",
    "                    progress();\n",
    "                    let loss = logpxZ.add(logpz);\n",
    "                    progress();\n",
    "                    loss = loss.sub(logqzX);\n",
    "                    progress();\n",
    "                    loss = tf.mean(loss).mul(-1);\n",
    "                    progress();\n",
    "                    return loss;\n",
    "                });\n",
    "            };\n",
    "\n",
    "            const optimizer = tf.train.adam(0.0001)\n",
    "\n",
    "            let l = 0;\n",
    "\n",
    "            let xs = tf.tensor(data.xs, [data.xs.length/784, 28,28,1], dtype='float32');\n",
    "            for (let i=0; i< data.numIterations; i++){\n",
    "                l = 0;\n",
    "                l += optimizer.minimize(()=>computeLoss(xs), true);\n",
    "                progress();\n",
    "            }\n",
    "            progress();\n",
    "            eWeights = getWeights(encoder);\n",
    "            progress();\n",
    "            dWeights = getWeights(decoder);\n",
    "            console.log(\"Done slice\");\n",
    "            progress(1.0);\n",
    "            \n",
    "            return { loss: l.arraySync(), eWeights, dWeights };\n",
    "        }, [encoderWeights, decoderWeights]);\n",
    "\n",
    "        job.on('accepted', ()=>{\n",
    "            console.log('Job accepted...');\n",
    "        });\n",
    "        job.on('status', (status)=>{\n",
    "            console.log('Got a status update: ', status);\n",
    "        });\n",
    "        job.on('result', (value)=>{\n",
    "            allEncoderWeights.push(value.result.eWeights);\n",
    "            allDecoderWeights.push(value.result.dWeights);\n",
    "        });\n",
    "        job.on('console', (output)=>{\n",
    "            console.log(output.message);\n",
    "        });\n",
    "        job.on('error', (err)=>{\n",
    "            console.log(err);\n",
    "        });\n",
    "\n",
    "        //job.requirements.environment.offscreenCanvas = true;\n",
    "\n",
    "        job.requires('dcp-polyfills/polyfills');\n",
    "        job.requires('aistensorflow/tfjs');\n",
    "\n",
    "\n",
    "        job.public.name = 'dcp-vae-testing';\n",
    "        console.log(\"Launching job\");\n",
    "        let results = await job.exec(compute.marketValue, accountKeystore);\n",
    "        \n",
    "        let avgEncWeights = averageWeights(allEncoderWeights);\n",
    "        let avgDecWeights = averageWeights(allDecoderWeights);\n",
    "        \n",
    "        encoder = setWeights(encoder, avgEncWeights);\n",
    "        decoder = setWeights(decoder, avgDecWeights);\n",
    "    }\n",
    "    console.log(\"Done executing job\");\n",
    "};\n",
    "\n",
    "main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(mnistResults[3]['img'])[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
